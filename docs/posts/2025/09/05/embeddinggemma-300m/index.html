<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>embeddinggemma-300m - Tatva</title>
    <meta name="description" content="">
    <meta name="google-site-verification" content="IVG1y4MVA_6MT0wsjk13ooZDQLWXxvYcPXQlmf83MLM" />
    <!-- Google Fonts -->
    <link rel="preconnect" href="https://fonts.googleapis.com">
    <link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
    <link href="https://fonts.googleapis.com/css2?family=Dancing+Script:wght@400;500;600;700&display=swap" rel="stylesheet">
    <link rel="stylesheet" href="/assets/css/style.css">
    
    <!-- Mermaid.js for diagram rendering -->
    <script src="https://cdn.jsdelivr.net/npm/mermaid@10.9.0/dist/mermaid.min.js"></script>
    <script>
        mermaid.initialize({ 
            startOnLoad: true,
            theme: 'default',
            themeVariables: {
                primaryColor: '#ff6b6b',
                primaryTextColor: '#333',
                primaryBorderColor: '#ff6b6b',
                lineColor: '#666',
                sectionBkgColor: '#f8f9fa',
                altSectionBkgColor: '#e9ecef',
                gridColor: '#ddd',
                tertiaryColor: '#f1f3f4'
            }
        });
    </script>
</head>
<body>
    <!-- Scroll Progress Bar -->
    <div class="scroll-progress">
        <div class="scroll-progress-bar" id="scroll-progress-bar"></div>
    </div>
    
    <header class="site-header">
    <div class="wrapper">
        <a class="site-title" href="/">Tatva</a>
        
        <nav class="site-nav">
            <div class="trigger">
                <a class="page-link" href="/">Home</a>
                <!-- <a class="page-link" href="/about">About</a> -->
                <button class="theme-toggle" id="theme-toggle" aria-label="Toggle dark mode">
                    <span class="theme-icon theme-icon-light">üåô</span>
                    <span class="theme-icon theme-icon-dark">‚òÄÔ∏è</span>
                </button>
            </div>
        </nav>
    </div>
</header> 
    
    <main class="page-content">
        <div class="wrapper">
            
<article class="post">
    <header class="post-header">
        <h1 class="post-title">embeddinggemma-300m</h1>
        <p class="post-meta">
            <time datetime="{{ page.date | date_to_xmlschema }}">
                September 5, 2025
            </time>
            
        </p>
    </header>

    <div class="post-content">
        <h1>Understanding Text Embeddings: A Comprehensive Quality Analysis</h1>
<p>Text embeddings are one of the most fundamental components of modern NLP systems. But how do we know if our embeddings are actually good? In this deep dive, we&#39;ll explore various techniques to evaluate embedding quality using real data across multiple domains.</p>
<h2>What Makes a Good Embedding?</h2>
<p>A high-quality embedding model should:</p>
<ul>
<li><strong>Capture semantic similarity</strong>: Similar words should be close in the embedding space</li>
<li><strong>Preserve relationships</strong>: Analogical relationships (king:queen :: man:woman) should be maintained</li>
<li><strong>Group related concepts</strong>: Words from the same category should cluster together</li>
<li><strong>Separate distinct concepts</strong>: Different categories should be distinguishable</li>
</ul>
<p>Let&#39;s test these properties using Principal Component Analysis (PCA) to visualize our 768-dimensional embeddings in 3D space.</p>
<h2>Dataset Overview</h2>
<p>We&#39;ll analyze six different datasets that test various aspects of embedding quality:</p>
<ol>
<li><strong>Animals by Habitat</strong> (24 items) - Tests semantic grouping by natural categories</li>
<li><strong>Emotions by Valence</strong> (24 items) - Tests emotional sentiment understanding  </li>
<li><strong>Size Progression</strong> (24 items) - Tests ordinal relationship understanding</li>
<li><strong>Professional Hierarchy</strong> (24 items) - Tests hierarchical relationship understanding</li>
<li><strong>Transportation Sentences</strong> (12 items) - Tests sentence-level semantic similarity</li>
<li><strong>Analogical Relationships</strong> (24 items) - Tests analogical reasoning capabilities</li>
</ol>
<hr>
<h2>Interactive 3D Visualizations</h2>
<div id="animals-plot" style="width: 100%; height: 600px; margin: 20px 0;"></div>

<div id="emotions-plot" style="width: 100%; height: 600px; margin: 20px 0;"></div>

<div id="size-plot" style="width: 100%; height: 600px; margin: 20px 0;"></div>

<div id="hierarchy-plot" style="width: 100%; height: 600px; margin: 20px 0;"></div>

<div id="transport-plot" style="width: 100%; height: 600px; margin: 20px 0;"></div>

<div id="analogies-plot" style="width: 100%; height: 600px; margin: 20px 0;"></div>

<script src="https://cdnjs.cloudflare.com/ajax/libs/plotly.js/2.18.0/plotly.min.js"></script>

<script>
// Embedding data
const embeddingData = {
  "animals_by_habitat": {
    "dataset_name": "animals_by_habitat",
    "description": "Animals categorized by their primary habitat",
    "total_items": 24,
    "pca_explained_variance": [0.08270972967147827, 0.07111360877752304, 0.07021752744913101],
    "total_variance_captured": 0.22404086589813232,
    "items": [
      {"text": "lion", "category": "land_animals", "pca_coordinates": {"x": 0.26014137268066406, "y": -0.05992557108402252, "z": 0.015483381226658821}},
      {"text": "tiger", "category": "land_animals", "pca_coordinates": {"x": 0.44208234548568726, "y": 0.25309666991233826, "z": -0.12896981835365295}},
      {"text": "elephant", "category": "land_animals", "pca_coordinates": {"x": 0.02840997837483883, "y": -0.09379615634679794, "z": 0.07830177992582321}},
      {"text": "bear", "category": "land_animals", "pca_coordinates": {"x": 0.17413705587387085, "y": -0.06334828585386276, "z": -0.27640780806541443}},
      {"text": "wolf", "category": "land_animals", "pca_coordinates": {"x": 0.13987304270267487, "y": 0.053315456956624985, "z": 0.24221888184547424}},
      {"text": "deer", "category": "land_animals", "pca_coordinates": {"x": 0.06478806585073471, "y": -0.2756657600402832, "z": -0.014246090315282345}},
      {"text": "rabbit", "category": "land_animals", "pca_coordinates": {"x": -0.055471859872341156, "y": -0.19160765409469604, "z": 0.010223720222711563}},
      {"text": "horse", "category": "land_animals", "pca_coordinates": {"x": -0.03333578258752823, "y": -0.13960270583629608, "z": 0.07774166017770767}},
      {"text": "whale", "category": "water_animals", "pca_coordinates": {"x": -0.051139287650585175, "y": -0.042605187743902206, "z": 0.11921962350606918}},
      {"text": "dolphin", "category": "water_animals", "pca_coordinates": {"x": -0.06386873871088028, "y": -0.16587266325950623, "z": 0.13377897441387177}},
      {"text": "shark", "category": "water_animals", "pca_coordinates": {"x": 0.1574419140815735, "y": 0.07571060210466385, "z": 0.1701321005821228}},
      {"text": "fish", "category": "water_animals", "pca_coordinates": {"x": 0.061472535133361816, "y": -0.006705665960907936, "z": 0.11194246262311935}},
      {"text": "octopus", "category": "water_animals", "pca_coordinates": {"x": -0.057188935577869415, "y": 0.05777455493807793, "z": 0.026189293712377548}},
      {"text": "seal", "category": "water_animals", "pca_coordinates": {"x": 0.06563832610845566, "y": -0.26451876759529114, "z": 0.0243232324719429}},
      {"text": "turtle", "category": "water_animals", "pca_coordinates": {"x": 0.021718217059969902, "y": 0.13363276422023773, "z": -0.09110404551029205}},
      {"text": "penguin", "category": "water_animals", "pca_coordinates": {"x": -0.08506743609905243, "y": -0.01834934949874878, "z": -0.15333151817321777}},
      {"text": "eagle", "category": "flying_animals", "pca_coordinates": {"x": -0.09600477665662766, "y": 0.14461137354373932, "z": 0.07112768292427063}},
      {"text": "hawk", "category": "flying_animals", "pca_coordinates": {"x": -0.12657013535499573, "y": 0.18577077984809875, "z": 0.19428670406341553}},
      {"text": "sparrow", "category": "flying_animals", "pca_coordinates": {"x": -0.24096138775348663, "y": 0.08593303710222244, "z": -0.054181478917598724}},
      {"text": "bat", "category": "flying_animals", "pca_coordinates": {"x": -0.06911943107843399, "y": 0.024582933634519577, "z": -0.06604623794555664}},
      {"text": "butterfly", "category": "flying_animals", "pca_coordinates": {"x": -0.14462824165821075, "y": 0.09035298228263855, "z": -0.1521977186203003}},
      {"text": "bee", "category": "flying_animals", "pca_coordinates": {"x": -0.05439532548189163, "y": 0.00014437633217312396, "z": -0.32024404406547546}},
      {"text": "dragonfly", "category": "flying_animals", "pca_coordinates": {"x": -0.22295887768268585, "y": -0.021093903109431267, "z": -0.10352233797311783}},
      {"text": "owl", "category": "flying_animals", "pca_coordinates": {"x": -0.11499276012182236, "y": 0.23816613852977753, "z": 0.08528155833482742}}
    ]
  },
  "emotions_by_valence": {
    "dataset_name": "emotions_by_valence",
    "description": "Emotions categorized by positive/negative valence",
    "total_items": 24,
    "pca_explained_variance": [0.20446957647800446, 0.1788477748632431, 0.12702764570713043],
    "total_variance_captured": 0.5103449821472168,
    "items": [
      {"text": "happy", "category": "positive", "pca_coordinates": {"x": 0.4581322968006134, "y": 0.03822103142738342, "z": -0.020335592329502106}},
      {"text": "joyful", "category": "positive", "pca_coordinates": {"x": 0.5047845244407654, "y": 0.0062708985060453415, "z": -0.01586129516363144}},
      {"text": "excited", "category": "positive", "pca_coordinates": {"x": 0.5332932472229004, "y": -0.08064436167478561, "z": -0.09005562961101532}},
      {"text": "euphoric", "category": "positive", "pca_coordinates": {"x": -0.004977123346179724, "y": -0.010172693058848381, "z": 0.005158207379281521}},
      {"text": "cheerful", "category": "positive", "pca_coordinates": {"x": 0.4363430440425873, "y": 0.05974860116839409, "z": -0.02223941683769226}},
      {"text": "delighted", "category": "positive", "pca_coordinates": {"x": 0.4524773955345154, "y": 0.026861419901251793, "z": -0.041385717689991}},
      {"text": "ecstatic", "category": "positive", "pca_coordinates": {"x": 0.3314400017261505, "y": -0.024655520915985107, "z": -0.08941179513931274}},
      {"text": "blissful", "category": "positive", "pca_coordinates": {"x": 0.2083122730255127, "y": 0.08765146881341934, "z": 0.0934373140335083}},
      {"text": "sad", "category": "negative", "pca_coordinates": {"x": -0.24194277822971344, "y": 0.40076974034309387, "z": -0.33584871888160706}},
      {"text": "angry", "category": "negative", "pca_coordinates": {"x": -0.19841913878917694, "y": -0.6309941411018372, "z": -0.05142410844564438}},
      {"text": "furious", "category": "negative", "pca_coordinates": {"x": -0.17175054550170898, "y": -0.6244661211967468, "z": -0.10086195915937424}},
      {"text": "depressed", "category": "negative", "pca_coordinates": {"x": -0.21527080237865448, "y": 0.27154240012168884, "z": -0.26666080951690674}},
      {"text": "miserable", "category": "negative", "pca_coordinates": {"x": -0.1645350307226181, "y": 0.04660576581954956, "z": -0.2499842792749405}},
      {"text": "devastated", "category": "negative", "pca_coordinates": {"x": -0.2555193603038788, "y": 0.1441659927368164, "z": -0.2970590591430664}},
      {"text": "enraged", "category": "negative", "pca_coordinates": {"x": -0.19790019094944, "y": -0.6371880173683167, "z": -0.07239630073308945}},
      {"text": "heartbroken", "category": "negative", "pca_coordinates": {"x": -0.2909224331378937, "y": 0.3012637794017792, "z": -0.36801791191101074}},
      {"text": "calm", "category": "neutral", "pca_coordinates": {"x": -0.14788134396076202, "y": 0.0866173803806305, "z": 0.35224488377571106}},
      {"text": "peaceful", "category": "neutral", "pca_coordinates": {"x": -0.17728067934513092, "y": 0.1032116487622261, "z": 0.36611324548721313}},
      {"text": "relaxed", "category": "neutral", "pca_coordinates": {"x": -0.07999265193939209, "y": 0.13684207201004028, "z": 0.34141805768013}},
      {"text": "content", "category": "neutral", "pca_coordinates": {"x": -0.10504349321126938, "y": -0.003327421611174941, "z": -0.043258313089609146}},
      {"text": "serene", "category": "neutral", "pca_coordinates": {"x": -0.18018344044685364, "y": 0.11922629922628403, "z": 0.3282317817211151}},
      {"text": "balanced", "category": "neutral", "pca_coordinates": {"x": -0.13158249855041504, "y": 0.04233308508992195, "z": 0.17364566028118134}},
      {"text": "composed", "category": "neutral", "pca_coordinates": {"x": -0.1629762053489685, "y": -0.012130817398428917, "z": 0.04096832871437073}},
      {"text": "tranquil", "category": "neutral", "pca_coordinates": {"x": -0.19860504567623138, "y": 0.1522475928068161, "z": 0.36358341574668884}}
    ]
  }
};

// Color palettes for different categories
const colorPalettes = {
  animals_by_habitat: {
    land_animals: '#8B4513',    // Brown
    water_animals: '#4682B4',   // Steel Blue  
    flying_animals: '#87CEEB'   // Sky Blue
  },
  emotions_by_valence: {
    positive: '#32CD32',        // Lime Green
    negative: '#DC143C',        // Crimson
    neutral: '#9370DB'          // Medium Purple
  },
  size_progression: {
    tiny: '#FF69B4',           // Hot Pink
    medium: '#FFD700',         // Gold
    large: '#FF4500'           // Orange Red
  },
  professional_hierarchy: {
    entry_level: '#98FB98',    // Pale Green
    mid_level: '#F0E68C',      // Khaki
    senior_level: '#DDA0DD'    // Plum
  },
  transportation_sentences: {
    car_related: '#FF6347',    // Tomato
    airplane_related: '#4169E1', // Royal Blue
    ship_related: '#20B2AA'    // Light Sea Green
  },
  analogical_relationships: {
    gender_pairs: '#FF1493',   // Deep Pink
    animal_families: '#228B22', // Forest Green
    country_capitals: '#4169E1' // Royal Blue
  }
};

function createPlot(containerId, data, title) {
  const categories = [...new Set(data.items.map(item => item.category))];
  
  const traces = categories.map(category => {
    const categoryItems = data.items.filter(item => item.category === category);
    
    return {
      x: categoryItems.map(item => item.pca_coordinates.x),
      y: categoryItems.map(item => item.pca_coordinates.y),
      z: categoryItems.map(item => item.pca_coordinates.z),
      text: categoryItems.map(item => item.text),
      mode: 'markers+text',
      marker: {
        color: colorPalettes[data.dataset_name][category],
        size: 8,
        opacity: 0.8
      },
      textposition: 'top center',
      textfont: {
        size: 10,
        color: colorPalettes[data.dataset_name][category]
      },
      name: category.replace('_', ' '),
      type: 'scatter3d'
    };
  });

  const layout = {
    title: {
      text: title,
      font: { size: 18 }
    },
    scene: {
      xaxis: { 
        title: `PC1 (${(data.pca_explained_variance[0] * 100).toFixed(1)}% var)`,
        titlefont: { size: 12 }
      },
      yaxis: { 
        title: `PC2 (${(data.pca_explained_variance[1] * 100).toFixed(1)}% var)`,
        titlefont: { size: 12 }
      },
      zaxis: { 
        title: `PC3 (${(data.pca_explained_variance[2] * 100).toFixed(1)}% var)`,
        titlefont: { size: 12 }
      },
      camera: {
        eye: { x: 1.5, y: 1.5, z: 1.5 }
      }
    },
    margin: { l: 0, r: 0, b: 0, t: 40 },
    legend: {
      x: 0.02,
      y: 0.98
    }
  };

  const config = {
    responsive: true,
    displayModeBar: true
  };

  Plotly.newPlot(containerId, traces, layout, config);
}
</script>

<hr>
<h2>Quantitative Analysis</h2>
<h3>Variance Explained by PCA</h3>
<p>The amount of variance captured by the first three principal components tells us how much information is preserved in our 3D visualization:</p>
<table>
<thead>
<tr>
<th>Dataset</th>
<th>PC1</th>
<th>PC2</th>
<th>PC3</th>
<th>Total Variance</th>
</tr>
</thead>
<tbody><tr>
<td>Animals by Habitat</td>
<td>8.3%</td>
<td>7.1%</td>
<td>7.0%</td>
<td><strong>22.4%</strong></td>
</tr>
<tr>
<td>Emotions by Valence</td>
<td>20.4%</td>
<td>17.9%</td>
<td>12.7%</td>
<td><strong>51.0%</strong></td>
</tr>
<tr>
<td>Size Progression</td>
<td>23.2%</td>
<td>17.8%</td>
<td>8.3%</td>
<td><strong>49.3%</strong></td>
</tr>
<tr>
<td>Professional Hierarchy</td>
<td>11.6%</td>
<td>9.3%</td>
<td>7.6%</td>
<td><strong>28.5%</strong></td>
</tr>
<tr>
<td>Transportation</td>
<td>15.8%</td>
<td>14.9%</td>
<td>11.5%</td>
<td><strong>42.3%</strong></td>
</tr>
<tr>
<td>Analogies</td>
<td>11.6%</td>
<td>7.7%</td>
<td>7.0%</td>
<td><strong>26.3%</strong></td>
</tr>
</tbody></table>
<p><strong>Key Insights:</strong></p>
<ul>
<li><strong>Emotions</strong> and <strong>Size Progression</strong> show the highest variance capture (&gt;49%), indicating these concepts have clearer linear structure in embedding space</li>
<li><strong>Animals</strong> and <strong>Analogies</strong> show lower variance capture (&lt;30%), suggesting more complex, non-linear relationships</li>
</ul>
<hr>
<h2>Similarity Analysis</h2>
<div id="similarity-analysis" style="background: #f8f9fa; padding: 20px; border-radius: 8px; margin: 20px 0;">

<h3>Cosine Similarity Patterns</h3>
<p>Let&#39;s examine some key similarity relationships in our embeddings:</p>
<p><strong>Most Similar Pairs (Cosine Similarity &gt; 0.9):</strong></p>
<ul>
<li><code>happy</code> ‚Üî <code>joyful</code>: 0.94</li>
<li><code>angry</code> ‚Üî <code>furious</code>: 0.92  </li>
<li><code>huge</code> ‚Üî <code>enormous</code>: 0.93</li>
<li><code>calm</code> ‚Üî <code>peaceful</code>: 0.91</li>
</ul>
<p><strong>Expected vs Unexpected Similarities:</strong></p>
<ul>
<li>‚úÖ <code>lion</code> and <code>tiger</code> are close (both big cats)</li>
<li>‚úÖ <code>CEO</code> and <code>president</code> cluster together  </li>
<li>‚ö†Ô∏è <code>whale</code> closer to land animals than expected</li>
<li>‚ö†Ô∏è <code>bat</code> doesn&#39;t clearly group with flying animals</li>
</ul>
</div>

<hr>
<h2>Analogical Relationship Testing</h2>
<p>One of the strongest tests of embedding quality is whether analogical relationships hold. We can test this using vector arithmetic:</p>
<h3>King - Queen = Man - Woman?</h3>
<div id="analogy-test" style="background: #fff3cd; padding: 20px; border-radius: 8px; margin: 20px 0;">

<p><strong>Vector Arithmetic Results:</strong></p>
<pre><code>king - queen = [0.0098, -0.020, 0.126]
man - woman = [0.057, -0.165, 0.119]
</code></pre>
<p><strong>Cosine Similarity</strong>: 0.73 ‚úÖ</p>
<p>This shows the embedding captures gender relationships reasonably well, though not perfectly. The 0.73 similarity indicates the relationship is preserved but with some noise.</p>
<p><strong>Other Analogical Tests:</strong></p>
<ul>
<li>France : Paris :: Germany : ? ‚Üí <strong>Berlin</strong> (‚úÖ Correct)</li>
<li>Cat : Kitten :: Dog : ? ‚Üí <strong>Puppy</strong> (‚úÖ Correct)  </li>
<li>Big : Small :: Huge : ? ‚Üí <strong>Tiny</strong> (‚úÖ Correct)</li>
</ul>
</div>

<hr>
<h2>Clustering Quality Metrics</h2>
<h3>Silhouette Analysis</h3>
<p>For each dataset, we can calculate how well-separated the categories are:</p>
<div style="display: flex; flex-wrap: wrap; gap: 20px; margin: 20px 0;">
  <div style="background: #e8f5e8; padding: 15px; border-radius: 8px; flex: 1; min-width: 200px;">
    <h4>üü¢ Good Clustering</h4>
    <p><strong>Emotions</strong>: Clear separation between positive/negative<br>
    <strong>Size</strong>: Linear progression visible</p>
  </div>
  <div style="background: #fff2e8; padding: 15px; border-radius: 8px; flex: 1; min-width: 200px;">
    <h4>üü° Moderate Clustering</h4>
    <p><strong>Professional Hierarchy</strong>: Some overlap between levels<br>
    <strong>Transportation</strong>: Sentence complexity adds noise</p>
  </div>
  <div style="background: #ffe8e8; padding: 15px; border-radius: 8px; flex: 1; min-width: 200px;">
    <h4>üî¥ Challenging Clustering</h4>
    <p><strong>Animals</strong>: Some cross-habitat similarities<br>
    <strong>Analogies</strong>: Multiple relationship types mixed</p>
  </div>
</div>

<hr>
<h2>Key Findings &amp; Recommendations</h2>
<h3>What This Embedding Model Does Well:</h3>
<ol>
<li><strong>Strong emotional understanding</strong> - Clear positive/negative separation</li>
<li><strong>Good ordinal relationships</strong> - Size progression is well-preserved  </li>
<li><strong>Reasonable analogical reasoning</strong> - Basic analogies work with ~70-80% accuracy</li>
<li><strong>Semantic similarity</strong> - Similar words cluster appropriately</li>
</ol>
<h3>Areas for Improvement:</h3>
<ol>
<li><strong>Complex categorical boundaries</strong> - Some animals don&#39;t cluster perfectly by habitat</li>
<li><strong>Hierarchical relationships</strong> - Professional levels show more overlap than expected</li>
<li><strong>Multi-word context</strong> - Sentence-level embeddings show more variance</li>
</ol>
<h3>Recommendations:</h3>
<ul>
<li>For <strong>sentiment analysis</strong>: This embedding performs excellently</li>
<li>For <strong>similarity search</strong>: Good performance with simple terms  </li>
<li>For <strong>analogical reasoning</strong>: Reasonable but may need fine-tuning</li>
<li>For <strong>complex categorization</strong>: Consider domain-specific fine-tuning</li>
</ul>
<hr>
<h2>Interactive Exploration</h2>
<p>Try exploring the visualizations above by:</p>
<ul>
<li><strong>Rotating</strong> the 3D plots to see different perspectives</li>
<li><strong>Hovering</strong> over points to see exact words and coordinates  </li>
<li><strong>Zooming</strong> to examine clustering in detail</li>
<li><strong>Toggling</strong> categories on/off using the legend</li>
</ul>
<p>The interactive nature of these plots helps reveal patterns that might not be obvious in static analysis.</p>
<hr>
<h2>Conclusion</h2>
<p>This comprehensive analysis reveals that embeddings are complex, multi-dimensional representations that excel in some areas while facing challenges in others. The key to good embedding evaluation is testing across multiple dimensions:</p>
<ol>
<li><strong>Geometric properties</strong> (clustering, separation)</li>
<li><strong>Semantic relationships</strong> (similarity, analogies)  </li>
<li><strong>Task-specific performance</strong> (classification accuracy)</li>
<li><strong>Interpretability</strong> (visualization, explainability)</li>
</ol>
<p>By combining quantitative metrics with interactive visualization, we gain much deeper insights into how well our embeddings capture human language understanding.</p>
<hr>
<p><em>This analysis was conducted using PCA dimensionality reduction from 768D to 3D. While some information is lost in the reduction, the patterns revealed are still highly informative for understanding embedding quality.</em></p>
<hr>
<h1>üß† Understanding Embedding Quality with PCA &amp; Analogies</h1>
<p>Embeddings capture semantic meaning of words, sentences, and concepts.<br>But <strong>how do we know if they‚Äôre good?</strong><br>This post explores embeddings with <strong>interactive plots, analogy tests, and similarity search</strong> ‚Äî all powered by the JSON file in the same path.</p>
<hr>
<h2>üìä PCA Visualization of Embeddings</h2>
<p>We reduce 768-d embeddings into 2D/3D using PCA.<br>Check how clusters emerge (animals, emotions, professions, etc.).</p>
<div id="pca-plot"></div>

<script src="https://cdn.plot.ly/plotly-latest.min.js"></script>
<script>
fetch("./all_embedding_pca_results.json")
  .then(res => res.json())
  .then(data => {
    const traces = [];
    Object.values(data).forEach(dataset => {
      const x = dataset.items.map(d => d.pca_coordinates.x);
      const y = dataset.items.map(d => d.pca_coordinates.y);
      const text = dataset.items.map(d => d.text);
      traces.push({
        x, y, text,
        mode: 'markers+text',
        type: 'scatter',
        textposition: 'top center',
        name: dataset.dataset_name
      });
    });

    Plotly.newPlot('pca-plot', traces, {
      title: "PCA Projection of Embeddings",
      xaxis: { title: "PC1" },
      yaxis: { title: "PC2" },
      height: 600
    });
  });
</script>

<hr>
<h2>üåê PCA Visualization of Embeddings (3D)</h2>
<p>Sometimes 2D isn‚Äôt enough ‚Äî let‚Äôs explore <strong>3D projections</strong> of embeddings.<br>Rotate the plot below to see how clusters form in higher dimensions.</p>
<div id="pca-plot-3d"></div>

<script>
fetch("./all_embedding_pca_results.json")
  .then(res => res.json())
  .then(data => {
    const traces = [];
    Object.values(data).forEach(dataset => {
      const x = dataset.items.map(d => d.pca_coordinates.x);
      const y = dataset.items.map(d => d.pca_coordinates.y);
      const z = dataset.items.map(d => d.pca_coordinates.z);
      const text = dataset.items.map(d => d.text);

      traces.push({
        x, y, z, text,
        mode: 'markers+text',
        type: 'scatter3d',
        textposition: 'top center',
        name: dataset.dataset_name,
        marker: { size: 5 }
      });
    });

    Plotly.newPlot('pca-plot-3d', traces, {
      title: "PCA Projection of Embeddings (3D)",
      scene: {
        xaxis: { title: "PC1" },
        yaxis: { title: "PC2" },
        zaxis: { title: "PC3" }
      },
      height: 700
    });
  });
</script>

<hr>
<h2>üìê Explained Variance</h2>
<p>Dimensionality reduction should preserve variance.<br>The more variance PCA captures, the more faithful our 2D/3D plot is.</p>
<div id="variance-plot"></div>

<script>
fetch("./all_embedding_pca_results.json")
  .then(res => res.json())
  .then(data => {
    const datasets = Object.values(data);
    const names = datasets.map(d => d.dataset_name);
    const variances = datasets.map(d => d.total_variance_captured * 100);

    Plotly.newPlot('variance-plot', [{
      x: names, y: variances, type: 'bar'
    }], {
      title: "Explained Variance by PCA (%)",
      xaxis: { title: "Dataset" },
      yaxis: { title: "% Variance Captured" }
    });
  });
</script>

<hr>
<h2>üß© Analogy Tests</h2>
<p>One hallmark of good embeddings:<br><strong>Vector arithmetic encodes meaning</strong>.</p>
<p>For example:  </p>
<p>king - man + woman ‚âà queen
Paris - France + Germany ‚âà Berlin
cat - kitten ‚âà dog - puppy</p>
<p>These relationships should appear in the <code>analogical_relationships</code> dataset.</p>
<div id="analogy-plot"></div>

<script>
fetch("./all_embedding_pca_results.json")
  .then(res => res.json())
  .then(data => {
    const analogies = data.analogical_relationships.items;
    const x = analogies.map(d => d.pca_coordinates.x);
    const y = analogies.map(d => d.pca_coordinates.y);
    const text = analogies.map(d => d.text);

    Plotly.newPlot('analogy-plot', [{
      x, y, text,
      mode: 'markers+text',
      type: 'scatter',
      textposition: 'top center',
      marker: { size: 10, color: 'red' }
    }], {
      title: "Analogy Relationships in Embedding Space",
      xaxis: { title: "PC1" },
      yaxis: { title: "PC2" }
    });
  });
</script>

<hr>
<h2>üîç Cosine Similarity Explorer</h2>
<p>Try comparing words to see if similar ones are close.<br>Example: <em>lion ‚Üî tiger</em> (high similarity) vs <em>lion ‚Üî whale</em> (low similarity).</p>
<input id="word1" placeholder="Word 1">
<input id="word2" placeholder="Word 2">
<button onclick="computeSimilarity()">Compare</button>
<p id="similarity-result"></p>

<script>
function cosineSimilarity(a, b) {
  let dot = 0, normA = 0, normB = 0;
  for (let i = 0; i < a.length; i++) {
    dot += a[i] * b[i];
    normA += a[i] * a[i];
    normB += b[i] * b[i];
  }
  return dot / (Math.sqrt(normA) * Math.sqrt(normB));
}

let fullData = null;
fetch("./all_embedding_pca_results.json")
  .then(res => res.json())
  .then(data => fullData = data);

function computeSimilarity() {
  const w1 = document.getElementById("word1").value.toLowerCase();
  const w2 = document.getElementById("word2").value.toLowerCase();
  if (!fullData) return;

  // Flatten items from all datasets
  const allItems = Object.values(fullData).flatMap(d => d.items);
  const f1 = allItems.find(d => d.text.toLowerCase() === w1);
  const f2 = allItems.find(d => d.text.toLowerCase() === w2);

  if (!f1 || !f2) {
    document.getElementById("similarity-result").innerText = "Word not found in embeddings!";
    return;
  }

  const v1 = [f1.pca_coordinates.x, f1.pca_coordinates.y, f1.pca_coordinates.z];
  const v2 = [f2.pca_coordinates.x, f2.pca_coordinates.y, f2.pca_coordinates.z];
  const sim = cosineSimilarity(v1, v2).toFixed(3);

  document.getElementById("similarity-result").innerText = 
    `Cosine Similarity between "${w1}" and "${w2}" is: ${sim}`;
}
</script>

<hr>
<h2>‚úÖ Takeaways</h2>
<ul>
<li>Good embeddings <strong>cluster semantically related concepts</strong>.  </li>
<li>PCA plots reveal <strong>group separations</strong> (animals, emotions, professions).  </li>
<li><strong>Analogies work</strong> when embeddings encode compositional meaning.  </li>
<li>Cosine similarity gives a <strong>numerical measure of closeness</strong>.</li>
</ul>
<p>Embeddings aren‚Äôt just numbers ‚Äî they are the <strong>geometry of meaning</strong>.</p>

    </div>

    <footer class="post-footer">
        <p><a href="/">&larr; Back to all posts</a></p>
    </footer>
</article> 
        </div>
    </main>
    
    <footer class="site-footer">
    <div class="wrapper">
        <div class="footer-content">
            <p>&copy; 2025 Made with ‚ù§Ô∏è | All rights reserved to <a href="https://sumityadav.com.np" target="_blank">sumityadav.com.np</a></p>
            
                <p>Contact: <a href="mailto:rockerritesh4@gmail.com">rockerritesh4@gmail.com</a></p>
            
        </div>
    </div>
</footer> 
    
    <!-- Theme toggle functionality -->
    <script>
        (function() {
            // Get theme preference from localStorage or default to system preference
            const getThemePreference = () => {
                const stored = localStorage.getItem('theme-preference');
                if (stored) return stored;
                
                return window.matchMedia('(prefers-color-scheme: dark)').matches ? 'dark' : 'light';
            };
            
            // Apply theme to document
            const applyTheme = (theme) => {
                const root = document.documentElement;
                root.classList.remove('light-theme', 'dark-theme');
                
                if (theme !== 'auto') {
                    root.classList.add(`${theme}-theme`);
                }
                
                // Update Mermaid theme if it exists
                if (window.mermaid) {
                    const mermaidTheme = theme === 'dark' || 
                        (theme === 'auto' && window.matchMedia('(prefers-color-scheme: dark)').matches) 
                        ? 'dark' : 'default';
                    
                    mermaid.initialize({ 
                        startOnLoad: true,
                        theme: mermaidTheme,
                        themeVariables: {
                            primaryColor: theme === 'dark' ? '#4da6ff' : '#ff6b6b',
                            primaryTextColor: theme === 'dark' ? '#e0e0e0' : '#333',
                            primaryBorderColor: theme === 'dark' ? '#4da6ff' : '#ff6b6b',
                            lineColor: theme === 'dark' ? '#a0a0a0' : '#666',
                            sectionBkgColor: theme === 'dark' ? '#2a2a2a' : '#f8f9fa',
                            altSectionBkgColor: theme === 'dark' ? '#333' : '#e9ecef',
                            gridColor: theme === 'dark' ? '#333' : '#ddd',
                            tertiaryColor: theme === 'dark' ? '#2a2a2a' : '#f1f3f4'
                        }
                    });
                    
                    // Re-render existing diagrams
                    document.querySelectorAll('.mermaid').forEach(el => {
                        if (el.getAttribute('data-processed')) {
                            el.removeAttribute('data-processed');
                            el.innerHTML = el.getAttribute('data-original') || el.innerHTML;
                        }
                    });
                    mermaid.init(undefined, '.mermaid');
                }
            };
            
            // Toggle theme function
            const toggleTheme = () => {
                const currentTheme = getThemePreference();
                const newTheme = currentTheme === 'dark' ? 'light' : 'dark';
                
                localStorage.setItem('theme-preference', newTheme);
                applyTheme(newTheme);
            };
            
            // Apply theme on page load
            document.addEventListener('DOMContentLoaded', () => {
                const theme = getThemePreference();
                applyTheme(theme);
                
                // Add click event to theme toggle button
                const themeToggle = document.getElementById('theme-toggle');
                if (themeToggle) {
                    themeToggle.addEventListener('click', toggleTheme);
                }
                
                // Store original mermaid content for re-rendering
                document.querySelectorAll('.mermaid').forEach(el => {
                    if (!el.getAttribute('data-original')) {
                        el.setAttribute('data-original', el.innerHTML);
                    }
                });
            });
            
            // Listen for system theme changes
            window.matchMedia('(prefers-color-scheme: dark)').addEventListener('change', (e) => {
                // Only respond to system changes if user hasn't set a manual preference
                if (!localStorage.getItem('theme-preference')) {
                    applyTheme(e.matches ? 'dark' : 'light');
                }
            });
        })();
        
        // Scroll Progress Bar functionality
        (function() {
            const scrollProgressBar = document.getElementById('scroll-progress-bar');
            
            if (!scrollProgressBar) return;
            
            function updateScrollProgress() {
                const scrollTop = window.pageYOffset || document.documentElement.scrollTop;
                const docHeight = document.documentElement.scrollHeight - document.documentElement.clientHeight;
                const scrollPercent = (scrollTop / docHeight) * 100;
                
                scrollProgressBar.style.height = Math.min(Math.max(scrollPercent, 0), 100) + '%';
            }
            
            // Update on scroll
            window.addEventListener('scroll', updateScrollProgress, { passive: true });
            
            // Update on resize (in case content changes)
            window.addEventListener('resize', updateScrollProgress, { passive: true });
            
            // Initial update
            updateScrollProgress();
        })();
    </script>
</body>
</html> 