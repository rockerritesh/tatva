<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Can You Predict a Network's Performance from Its Geometry Alone? - Tatva</title>
    <meta name="description" content="">
    <meta name="google-site-verification" content="IVG1y4MVA_6MT0wsjk13ooZDQLWXxvYcPXQlmf83MLM" />
    <!-- Google Fonts -->
    <link rel="preconnect" href="https://fonts.googleapis.com">
    <link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
    <link href="https://fonts.googleapis.com/css2?family=Crimson+Pro:wght@400;600;700&family=Inter:wght@400;500;600;700&display=swap" rel="stylesheet">
    <link rel="stylesheet" href="/assets/css/style.css">
    
    <!-- Mermaid.js for diagram rendering -->
    <script src="https://cdn.jsdelivr.net/npm/mermaid@10.9.0/dist/mermaid.min.js"></script>
    <script>
        mermaid.initialize({ 
            startOnLoad: true,
            theme: 'default',
            themeVariables: {
                primaryColor: '#ff6b6b',
                primaryTextColor: '#333',
                primaryBorderColor: '#ff6b6b',
                lineColor: '#666',
                sectionBkgColor: '#f8f9fa',
                altSectionBkgColor: '#e9ecef',
                gridColor: '#ddd',
                tertiaryColor: '#f1f3f4'
            }
        });
    </script>
</head>
<body>
    <!-- Scroll Progress Bar -->
    <div class="scroll-progress">
        <div class="scroll-progress-bar" id="scroll-progress-bar"></div>
    </div>
    
    <header class="site-header">
    <div class="wrapper">
        <a class="site-title" href="/">Tatva</a>
        
        <nav class="site-nav">
            <div class="trigger">
                <a class="page-link" href="/">Home</a>
                <!-- <a class="page-link" href="/about">About</a> -->
                <button class="theme-toggle" id="theme-toggle" aria-label="Toggle dark mode">
                    <span class="theme-icon theme-icon-light">üåô</span>
                    <span class="theme-icon theme-icon-dark">‚òÄÔ∏è</span>
                </button>
            </div>
        </nav>
    </div>
</header> 
    
    <main class="page-content">
        <div class="wrapper">
            <div class="main-container">
                <div class="content-area">
                    
<article class="post">
    <header class="post-header">
        <h1 class="post-title">Can You Predict a Network's Performance from Its Geometry Alone?</h1>
        <p class="post-meta">
            <time datetime="{{ page.date | date_to_xmlschema }}">
                February 14, 2026
            </time>
            
        </p>
    </header>

    <div class="post-content">
        <script>
  window.MathJax = {
    tex: { inlineMath: [['$','$'], ['\\(','\\)']], displayMath: [['$$','$$'], ['\\[','\\]']] },
    svg: { fontCache: 'global' }
  };
</script>
<script src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-svg.js" async></script>

<h1>Can You Predict a Network&#39;s Performance from Its Geometry Alone?</h1>
<p><em>We show that two unsupervised geometric metrics, effective dimension and total compression, predict neural network accuracy across 92+ models spanning vision, NLP, and language modeling, without requiring labels.</em></p>
<hr>
<h2>Introduction</h2>
<p>What if you could assess a neural network&#39;s quality without ever running it on labeled data?</p>
<p>Predicting how well a neural network will generalize remains one of deep learning&#39;s fundamental challenges. Classical theory based on parameter counts and norms has repeatedly failed to explain why overparameterized networks generalize at all [1][2]. The most successful generalization measures require access to training data, labels, and often the training process itself [3].</p>
<p>We take a different approach. Instead of analyzing weights or training dynamics, we look at the <strong>shape of the learned representations</strong> ‚Äî the geometry of the high-dimensional spaces that neural networks create as they transform input data through successive layers.</p>
<p>Our main finding is striking: <strong>two simple, completely unsupervised geometric metrics predict neural network accuracy</strong> across 92+ pretrained models spanning computer vision, natural language processing, and language modeling. These metrics ‚Äî <em>effective dimension</em> and <em>total compression</em> ‚Äî require only unlabeled data fed through the network, with no knowledge of ground truth labels or training history.</p>
<p>Explore the relationship yourself in the interactive plot below. Each point is a pretrained model; hover to see details, and click the legend to filter by architecture family.</p>
<div style="width: 100%; margin: 20px 0;">
  <iframe src="/posts/2026/02/14/geometric-signatures/fig1_model_explorer.html" frameborder="0" scrolling="no" height="620px" width="100%"></iframe>
</div>

<h2>What Is Representation Geometry?</h2>
<p>Neural networks transform input data through a sequence of layers, creating intermediate <strong>representations</strong> ‚Äî high-dimensional vectors that encode increasingly abstract features. A ResNet-50, for example, transforms a 224x224 image through dozens of layers, each producing activations that live in spaces with hundreds or thousands of dimensions.</p>
<p>But not all of these dimensions are equally important. Much like how a sheet of paper is technically three-dimensional but effectively two-dimensional, neural network representations often occupy a lower-dimensional subspace of their ambient space. The question is: <em>how much</em> lower?</p>
<p>We answer this with two metrics, both computable from activations alone.</p>
<h3>Effective Dimension</h3>
<p>Given a set of activations at any layer, we compute the covariance matrix and extract its eigenvalues $$\lambda_1, \lambda_2, \ldots, \lambda_D$$. The <strong>effective dimension</strong> is the participation ratio:</p>
<p>$$d_{\text{eff}} = \frac{\left(\sum_i \lambda_i\right)^2}{\sum_i \lambda_i^2}$$</p>
<p>This measures &quot;how many dimensions are actually being used&quot; [4]. If all eigenvalues are equal, $$d_{\text{eff}} = D$$ (using all dimensions). If a single eigenvalue dominates, $$d_{\text{eff}} \approx 1$$.</p>
<p>To build intuition, explore the eigenvalue spectra of four models below. Notice how better-performing models tend to have more concentrated spectra ‚Äî fewer dimensions carrying most of the variance ‚Äî but the effective dimension captures different aspects depending on the layer and architecture.</p>
<div style="width: 100%; margin: 20px 0;">
  <iframe src="/posts/2026/02/14/geometric-signatures/fig2_eigenvalue_explorer.html" frameborder="0" scrolling="no" height="570px" width="100%"></iframe>
</div>

<h3>Total Compression</h3>
<p>While effective dimension captures the geometry at a single layer, <strong>total compression</strong> captures how the network reshapes information from input to output:</p>
<p>$$C_{\text{total}} = \log\frac{d_{\text{eff}}^{\text{input}}}{d_{\text{eff}}^{\text{output}}}$$</p>
<p>A positive value means the network <em>compresses</em> ‚Äî reducing the effective dimensionality of representations from input to output. This compression reflects the network&#39;s ability to distill raw input features into a compact, task-relevant code. Networks that compress more tend to have learned more structured, lower-dimensional representations at their final layer.</p>
<h2>The Main Finding</h2>
<p>Across 52 pretrained vision models from 13 architecture families (ResNets, VGGs, EfficientNets, Vision Transformers, Swin Transformers, and more), we find remarkably strong correlations between geometry and accuracy:</p>
<ul>
<li><strong>Output effective dimension</strong>: partial $$r = 0.746$$ ($$p &lt; 10^{-10}$$) ‚Äî the strongest single predictor</li>
<li><strong>Total compression</strong>: partial $$r = -0.720$$ ($$p &lt; 10^{-9}$$)</li>
</ul>
<p>The key word here is <strong>partial</strong> ‚Äî these correlations control for model size (number of parameters). Geometry predicts accuracy <em>independently</em> of model capacity. A small model with good geometry outperforms a large model with poor geometry.</p>
<p>Use the dashboard below to explore how different geometric metrics relate to each other and to accuracy. The dropdowns let you select any pair of metrics for the X and Y axes.</p>
<div style="width: 100%; margin: 20px 0;">
  <iframe src="/posts/2026/02/14/geometric-signatures/fig3_correlation_dashboard.html" frameborder="0" scrolling="no" height="620px" width="100%"></iframe>
</div>

<p>Perhaps most remarkably, these metrics are <strong>completely unsupervised</strong>. They are computed solely from the activations produced by feeding unlabeled data through the network. No labels, no training loss, no gradient information ‚Äî just the shape of the learned representations.</p>
<h2>Does This Generalize Across Domains?</h2>
<p>A natural question: is this a vision-specific phenomenon, or something more fundamental?</p>
<p>We tested across three domains:</p>
<ol>
<li><strong>Computer Vision</strong>: 52 pretrained models on CIFAR-10 and ImageNet, spanning 13 architecture families including both CNNs and Transformers</li>
<li><strong>NLP Encoders</strong>: 8 transformer encoder models (BERT variants) fine-tuned on SST-2 sentiment analysis ‚Äî correlation $$r = -0.96$$ ($$R^2 = 0.92$$)</li>
<li><strong>Decoder LLMs</strong>: 7 autoregressive language models (GPT-2 variants and Pythia) fine-tuned on AG News classification</li>
</ol>
<p>The relationship holds across all three, but with an important nuance: <strong>the direction flips</strong>. Encoder-style models (vision, BERT) compress representations ‚Äî higher compression correlates with better accuracy. Decoder-style models (GPT-2, Pythia) <em>expand</em> representations through their layers, yet effective dimension at the output still correlates with performance.</p>
<p>This asymmetry may reflect fundamental architectural differences: encoders are designed to distill information into compact codes, while autoregressive decoders maintain rich, high-dimensional representations to predict the next token [5].</p>
<div style="width: 100%; margin: 20px 0;">
  <iframe src="/posts/2026/02/14/geometric-signatures/fig4_domain_explorer.html" frameborder="0" scrolling="no" height="620px" width="100%"></iframe>
</div>

<h2>Is the Relationship Causal?</h2>
<p>Observational correlations are suggestive, but can we establish a stronger link? We run two intervention experiments that perturb the geometry of a trained network and measure the effect on accuracy.</p>
<h3>Degradation via Noise</h3>
<p>We inject noise directly into the final-layer activations of a trained ResNet-18. We test four noise types: Gaussian, uniform, dropout, and salt-and-pepper, at noise levels from 0.1 to 0.5.</p>
<p>The result is consistent across all noise types: <strong>noise increases effective dimension</strong> (by adding spurious, information-destroying dimensions to the representation) while <strong>accuracy drops</strong>. The pooled correlation between effective dimension change and accuracy change is $$r = -0.94$$ ($$p &lt; 10^{-9}$$).</p>
<p>This is exactly what we&#39;d predict if geometry <em>causally determines</em> classification performance: degrading the geometric structure directly harms the network&#39;s ability to classify.</p>
<div style="width: 100%; margin: 20px 0;">
  <iframe src="/posts/2026/02/14/geometric-signatures/fig5_noise_intervention.html" frameborder="0" scrolling="no" height="520px" width="100%"></iframe>
</div>

<h3>Preservation via PCA</h3>
<p>The complementary experiment: instead of degrading geometry, we <em>purify</em> it. We project final-layer activations onto their top principal components, discarding the rest, then measure classification accuracy.</p>
<p>The results are remarkable. At 95% variance preserved, <strong>only 16 PCA components are needed</strong> (out of 512 in the original representation), and accuracy drops by merely 0.04 percentage points. This confirms that the learned representations are remarkably low-dimensional ‚Äî the network has concentrated nearly all task-relevant information into a tiny subspace.</p>
<div style="width: 100%; margin: 20px 0;">
  <iframe src="/posts/2026/02/14/geometric-signatures/fig6_pca_intervention.html" frameborder="0" scrolling="no" height="570px" width="100%"></iframe>
</div>

<p>This connects to the information bottleneck theory [6][7]: effective networks learn to compress input information, retaining only what&#39;s relevant for the task. Our effective dimension metric quantifies exactly this compression, and the PCA intervention confirms it&#39;s not an artifact ‚Äî the low dimensionality reflects genuine structure.</p>
<h2>When Does Geometry Emerge During Training?</h2>
<p>If geometric structure is predictive of final performance, when does it emerge? We train 11 architectures from scratch on CIFAR-10 for 50 epochs, tracking all geometric metrics at 9 time points.</p>
<p>The key finding: <strong>geometric structure becomes predictive early</strong>. By epoch 5-10, effective dimension and silhouette score already differentiate models that will achieve high final accuracy from those that won&#39;t. Geometry is a <em>leading indicator</em> ‚Äî it settles before accuracy plateaus.</p>
<p>This has practical implications: you could monitor geometric metrics during training to get early signals about final performance, potentially saving computational resources by abandoning runs with poor geometric trajectories.</p>
<div style="width: 100%; margin: 20px 0;">
  <iframe src="/posts/2026/02/14/geometric-signatures/fig7_training_dynamics.html" frameborder="0" scrolling="no" height="720px" width="100%"></iframe>
</div>

<h2>What Does This Mean?</h2>
<p>Our findings suggest that the geometry of learned representations encodes fundamental information about model quality that transcends architecture, domain, and scale. Two unsupervised metrics ‚Äî effective dimension and total compression ‚Äî provide a surprisingly complete picture of a network&#39;s classification ability.</p>
<p><strong>Practical implications:</strong></p>
<ul>
<li><strong>Unsupervised model assessment</strong>: Evaluate pretrained models without labeled data ‚Äî useful for model selection, quality control, and comparing checkpoints</li>
<li><strong>Architecture search guidance</strong>: Geometric metrics could serve as cheap proxy objectives for neural architecture search</li>
<li><strong>Training monitoring</strong>: Track geometric evolution as an early indicator of final performance</li>
</ul>
<p><strong>Connection to GRaM themes</strong>: This work reinforces the view that geometry is not merely a convenient lens for understanding representations ‚Äî it reveals <em>fundamental structure</em> that directly determines function [8][9]. The strong correlation between unsupervised geometric metrics and supervised performance suggests that good representations converge toward a common geometric signature, consistent with the platonic representation hypothesis [5].</p>
<p><div class="mermaid">graph LR
    A[Pretrained Model] --> B[Feed Unlabeled Data]
    B --> C[Extract Activations]
    C --> D[Compute Effective Dimension]
    C --> E[Compute Total Compression]
    D --> F{Compare to Baselines}
    E --> F
    F --> G[Model Quality Assessment]</div></p>
<p><strong>Limitations and future directions:</strong></p>
<ul>
<li>Correlation strength varies by domain ‚Äî strongest for vision, weaker for decoder LLMs</li>
<li>The encoder/decoder asymmetry deserves deeper theoretical investigation</li>
<li>Extending to generative models (diffusion, GANs) and multi-modal architectures remains open</li>
<li>Connecting effective dimension to information-theoretic quantities like mutual information could provide theoretical grounding</li>
</ul>
<hr>
<h3>References</h3>
<ol>
<li>Zhang, C. et al. &quot;Understanding deep learning (still) requires rethinking generalization.&quot; <em>Communications of the ACM</em>, 2021.</li>
<li>Neyshabur, B. et al. &quot;Exploring generalization in deep nets.&quot; <em>NeurIPS</em>, 2017.</li>
<li>Jiang, Y. et al. &quot;Fantastic generalization measures and where to find them.&quot; <em>ICLR</em>, 2020.</li>
<li>Roy, O. &amp; Bhatt, R. &quot;Effective dimensionality of random vectors.&quot; <em>IEEE Transactions on Information Theory</em>, 2007.</li>
<li>Huh, M. et al. &quot;The platonic representation hypothesis.&quot; <em>ICML</em>, 2024.</li>
<li>Tishby, N. et al. &quot;The information bottleneck method.&quot; <em>arXiv preprint physics/0004057</em>, 2000.</li>
<li>Shwartz-Ziv, R. &amp; Tishby, N. &quot;Opening the black box of deep neural networks via information.&quot; <em>arXiv:1703.00810</em>, 2017.</li>
<li>Ansuini, A. et al. &quot;Intrinsic dimension of data representations in deep neural networks.&quot; <em>NeurIPS</em>, 2019.</li>
<li>Papyan, V. et al. &quot;Prevalence of neural collapse during the terminal phase of deep learning training.&quot; <em>PNAS</em>, 2020.</li>
</ol>

    </div>

    <div class="citation-section">
    <h3 class="citation-title">üìö How to Cite This Post</h3>
    
    <div class="citation-formats">
        <!-- BibTeX Citation -->
        <div class="citation-format">
            <h4>BibTeX</h4>
            <div class="citation-box">
                <pre class="citation-text" id="bibtex-citation">@article&#123;yadav{{ page.date | date: "%Y" }}{{ page.title | slugify | replace: '-', '' }},
    title = &#123;Can You Predict a Network's Performance from Its Geometry Alone?&#125;,
    author = &#123;Sumit Yadav&#125;,
    journal = &#123;Tatva&#125;,
    year = &#123;{{ page.date | date: "%Y" }}&#125;,
    month = &#123;{{ page.date | date: "%B" }}&#125;,
    day = &#123;{{ page.date | date: "%d" }}&#125;,
    url = &#123;https://tatva.sumityadav.com.np/posts/2026/02/14/geometric-signatures/&#125;,
    note = &#123;Accessed: {{ site.time | date: "%B %d, %Y" }}&#125;
&#125;</pre>
                <button class="copy-button" onclick="copyToClipboard('bibtex-citation')" title="Copy BibTeX">
                    üìã Copy BibTeX
                </button>
            </div>
        </div>
        
        <!-- APA Citation -->
        <div class="citation-format">
            <h4>APA Style</h4>
            <div class="citation-box">
                <pre class="citation-text" id="apa-citation">Yadav, S. ({{ page.date | date: "%Y, %B %d" }}). Can You Predict a Network's Performance from Its Geometry Alone?. <em>." <em>Tatva</em>, {{ page.date | date: "%d %b %Y" }}, https://tatva.sumityadav.com.np." Tatva. {{ page.date | date: "%B %d, %Y" }}. https://tatva.sumityadav.com.np/posts/2026/02/14/geometric-signatures/.</pre>
                <button class="copy-button" onclick="copyToClipboard('chicago-citation')" title="Copy Chicago">
                    üìã Copy Chicago
                </button>
            </div>
        </div>
    </div>
    
    <div class="citation-note">
        <p><strong>Note:</strong> This citation format is automatically generated. Please verify and adjust according to your institution's specific requirements.</p>
    </div>
</div>

<script>
function copyToClipboard(elementId) {
    const element = document.getElementById(elementId);
    const text = element.textContent || element.innerText;
    
    // Create a temporary textarea element
    const textarea = document.createElement('textarea');
    textarea.value = text;
    document.body.appendChild(textarea);
    
    // Select and copy the text
    textarea.select();
    textarea.setSelectionRange(0, 99999); // For mobile devices
    
    try {
        document.execCommand('copy');
        
        // Update button text to show success
        const button = element.nextElementSibling;
        const originalText = button.textContent;
        button.textContent = '‚úÖ Copied!';
        button.style.background = 'var(--link-color)';
        button.style.color = 'white';
        
        // Reset button after 2 seconds
        setTimeout(() => {
            button.textContent = originalText;
            button.style.background = '';
            button.style.color = '';
        }, 2000);
        
    } catch (err) {
        console.error('Failed to copy text: ', err);
        alert('Failed to copy citation. Please select and copy manually.');
    }
    
    // Remove the temporary textarea
    document.body.removeChild(textarea);
}
</script>

    <footer class="post-footer">
        <p><a href="/">&larr; Back to all posts</a></p>
    </footer>
</article> 
                </div>
                <aside class="sidebar">
    <div class="profile-card">
        <div class="profile-image">
            
            <img src="https://avatars.githubusercontent.com/rockerritesh" alt="Sumit Yadav" onerror="this.style.display='none'; this.nextElementSibling.style.display='flex';">
            
            <div class="profile-placeholder" style="display: none;">
                <span>{{ site.author.name | slice: 0 }}</span>
            </div>
        </div>
        
        <div class="profile-info">
            <h2 class="profile-name">Sumit Yadav</h2>
            <p class="profile-title">Research Scientist & Developer</p>
            <p class="profile-location">üìç Nepal</p>
            
            
            <p class="profile-bio">AI/ML researcher passionate about building intelligent systems and exploring the intersection of technology and human creativity.</p>
            
            
            <div class="profile-links">
                
                <a href="mailto:rockerritesh4@gmail.com" class="profile-link" title="Email">
                    üìß Email
                </a>
                
                
                
                <a href="https://github.com/rockerritesh" class="profile-link" title="GitHub" target="_blank">
                    üêô GitHub
                </a>
                
                
                
                <a href="https://linkedin.com/in/rockerritesh" class="profile-link" title="LinkedIn" target="_blank">
                    üíº LinkedIn
                </a>
                
                
                
                <a href="https://twitter.com/rocker_ritesh" class="profile-link" title="Twitter" target="_blank">
                    üê¶ Twitter
                </a>
                
                
                
                <a href="https://scholar.google.com/citations?user=ag74ytsAAAAJ&hl=en" class="profile-link" title="Google Scholar" target="_blank">
                    üéì Scholar
                </a>
                
                
                
                <a href="https://sumityadav.com.np" class="profile-link" title="Website" target="_blank">
                    üåê Website
                </a>
                
            </div>
        </div>
    </div>
    
    <div class="research-highlights">
        <h3>Research Highlights</h3>
        <div class="highlight-section">
            <h4>AI & Machine Learning</h4>
            <ul>
                <li>Large Language Models</li>
                <li>Deep Learning Systems</li>
                <li>Natural Language Processing</li>
                <li>Computer Vision</li>
            </ul>
        </div>
        
        <div class="highlight-section">
            <h4>Software Development</h4>
            <ul>
                <li>Full-Stack Development</li>
                <li>Backend Systems</li>
                <li>API Design</li>
                <li>DevOps & Cloud</li>
            </ul>
        </div>
        
        <div class="highlight-section">
            <h4>Current Focus</h4>
            <ul>
                <li>AI Agent Development</li>
                <li>Model Optimization</li>
                <li>Research & Innovation</li>
                <li>Open Source Projects</li>
            </ul>
        </div>
    </div>
    
    <!-- <div class="recent-posts">
        <h3>Recent Posts</h3>
        <ul class="sidebar-post-list">
            
        </ul>
    </div> -->
</aside>

            </div>
        </div>
    </main>
    
    <footer class="site-footer">
    <div class="wrapper">
        <div class="footer-content">
            <p>&copy; 2026 Made with ‚ù§Ô∏è | All rights reserved to <a href="https://sumityadav.com.np" target="_blank">sumityadav.com.np</a></p>
            <p>Licensed under <a href="https://github.com/rockerritesh/tatva/blob/main/LICENSE" target="_blank">Apache License 2.0</a></p>
            
                <p>Contact: <a href="mailto:rockerritesh4@gmail.com">rockerritesh4@gmail.com</a></p>
            
        </div>
    </div>
</footer> 
    
    <!-- Theme toggle functionality -->
    <script>
        (function() {
            // Get theme preference from localStorage or default to system preference
            const getThemePreference = () => {
                const stored = localStorage.getItem('theme-preference');
                if (stored) return stored;
                
                return window.matchMedia('(prefers-color-scheme: dark)').matches ? 'dark' : 'light';
            };
            
            // Apply theme to document
            const applyTheme = (theme) => {
                const root = document.documentElement;
                root.classList.remove('light-theme', 'dark-theme');
                
                if (theme !== 'auto') {
                    root.classList.add(`${theme}-theme`);
                }
                
                // Update Mermaid theme if it exists
                if (window.mermaid) {
                    const mermaidTheme = theme === 'dark' || 
                        (theme === 'auto' && window.matchMedia('(prefers-color-scheme: dark)').matches) 
                        ? 'dark' : 'default';
                    
                    mermaid.initialize({ 
                        startOnLoad: true,
                        theme: mermaidTheme,
                        themeVariables: {
                            primaryColor: theme === 'dark' ? '#4da6ff' : '#ff6b6b',
                            primaryTextColor: theme === 'dark' ? '#e0e0e0' : '#333',
                            primaryBorderColor: theme === 'dark' ? '#4da6ff' : '#ff6b6b',
                            lineColor: theme === 'dark' ? '#a0a0a0' : '#666',
                            sectionBkgColor: theme === 'dark' ? '#2a2a2a' : '#f8f9fa',
                            altSectionBkgColor: theme === 'dark' ? '#333' : '#e9ecef',
                            gridColor: theme === 'dark' ? '#333' : '#ddd',
                            tertiaryColor: theme === 'dark' ? '#2a2a2a' : '#f1f3f4'
                        }
                    });
                    
                    // Re-render existing diagrams
                    document.querySelectorAll('.mermaid').forEach(el => {
                        if (el.getAttribute('data-processed')) {
                            el.removeAttribute('data-processed');
                            el.innerHTML = el.getAttribute('data-original') || el.innerHTML;
                        }
                    });
                    mermaid.init(undefined, '.mermaid');
                }
            };
            
            // Toggle theme function
            const toggleTheme = () => {
                const currentTheme = getThemePreference();
                const newTheme = currentTheme === 'dark' ? 'light' : 'dark';
                
                localStorage.setItem('theme-preference', newTheme);
                applyTheme(newTheme);
            };
            
            // Apply theme on page load
            document.addEventListener('DOMContentLoaded', () => {
                const theme = getThemePreference();
                applyTheme(theme);
                
                // Add click event to theme toggle button
                const themeToggle = document.getElementById('theme-toggle');
                if (themeToggle) {
                    themeToggle.addEventListener('click', toggleTheme);
                }
                
                // Store original mermaid content for re-rendering
                document.querySelectorAll('.mermaid').forEach(el => {
                    if (!el.getAttribute('data-original')) {
                        el.setAttribute('data-original', el.innerHTML);
                    }
                });
            });
            
            // Listen for system theme changes
            window.matchMedia('(prefers-color-scheme: dark)').addEventListener('change', (e) => {
                // Only respond to system changes if user hasn't set a manual preference
                if (!localStorage.getItem('theme-preference')) {
                    applyTheme(e.matches ? 'dark' : 'light');
                }
            });
        })();
        
        // Scroll Progress Bar functionality
        (function() {
            const scrollProgressBar = document.getElementById('scroll-progress-bar');
            
            if (!scrollProgressBar) return;
            
            function updateScrollProgress() {
                const scrollTop = window.pageYOffset || document.documentElement.scrollTop;
                const docHeight = document.documentElement.scrollHeight - document.documentElement.clientHeight;
                const scrollPercent = (scrollTop / docHeight) * 100;
                
                scrollProgressBar.style.height = Math.min(Math.max(scrollPercent, 0), 100) + '%';
            }
            
            // Update on scroll
            window.addEventListener('scroll', updateScrollProgress, { passive: true });
            
            // Update on resize (in case content changes)
            window.addEventListener('resize', updateScrollProgress, { passive: true });
            
            // Initial update
            updateScrollProgress();
        })();
    </script>
</body>
</html> 